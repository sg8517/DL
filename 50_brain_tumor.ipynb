{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKIX1Fe1iCkZ",
        "outputId": "afe623fb-ead4-4cda-9213-c16bc6c70d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "RxhWupebia2R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LGcCgfO1if_o",
        "outputId": "7f397762-269f-4c2e-b560-272f3609792c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/trail 3 brain tumor dataset/Training',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYVgnqBjijZA",
        "outputId": "5c24ff97-0929-4d1b-efab-3f6a3b580198"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/trail 3 brain tumor dataset/Testing',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqviMozOi_xc",
        "outputId": "5af94b2b-c3e8-48c1-eb2f-ff4812cf504c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 82 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "ouhMvTO0jYe_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "id": "QwHmtFbUjfcL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "sSUtNM20jhFM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "YMU7SxsEjkEZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "sozNJQCujnBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "nKBWySCFjqis"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "Btn4ZiF2juL6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "FYZ9lA_XjyOY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kSt5Pv8j13x",
        "outputId": "07a4eb5e-9c03-4c5b-8300-7bcc804eb4cc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 39s 12s/step - loss: 0.6859 - accuracy: 0.5400 - val_loss: 0.5694 - val_accuracy: 0.6951\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 2s 455ms/step - loss: 0.6197 - accuracy: 0.7000 - val_loss: 0.5351 - val_accuracy: 0.7195\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 2s 439ms/step - loss: 0.5832 - accuracy: 0.7600 - val_loss: 0.5015 - val_accuracy: 0.7195\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 2s 434ms/step - loss: 0.5733 - accuracy: 0.7200 - val_loss: 0.4746 - val_accuracy: 0.7683\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.5496 - accuracy: 0.8400 - val_loss: 0.4648 - val_accuracy: 0.7927\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 2s 683ms/step - loss: 0.4844 - accuracy: 0.8300 - val_loss: 0.4777 - val_accuracy: 0.7927\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.4176 - accuracy: 0.8600 - val_loss: 0.4352 - val_accuracy: 0.8171\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 2s 446ms/step - loss: 0.3663 - accuracy: 0.8800 - val_loss: 0.5129 - val_accuracy: 0.8049\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 2s 473ms/step - loss: 0.3252 - accuracy: 0.8600 - val_loss: 0.4988 - val_accuracy: 0.8171\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 2s 455ms/step - loss: 0.3413 - accuracy: 0.9000 - val_loss: 0.7921 - val_accuracy: 0.7927\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 2s 443ms/step - loss: 0.2702 - accuracy: 0.9200 - val_loss: 0.5709 - val_accuracy: 0.8293\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 2s 454ms/step - loss: 0.2355 - accuracy: 0.9300 - val_loss: 0.7558 - val_accuracy: 0.8171\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 2s 444ms/step - loss: 0.2050 - accuracy: 0.9000 - val_loss: 0.5378 - val_accuracy: 0.7439\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 2s 451ms/step - loss: 0.3729 - accuracy: 0.8000 - val_loss: 1.6078 - val_accuracy: 0.7195\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 2s 434ms/step - loss: 0.3830 - accuracy: 0.8500 - val_loss: 0.4494 - val_accuracy: 0.9024\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 2s 464ms/step - loss: 0.2452 - accuracy: 0.9300 - val_loss: 1.3088 - val_accuracy: 0.7439\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 2s 449ms/step - loss: 0.4023 - accuracy: 0.8500 - val_loss: 0.7258 - val_accuracy: 0.8171\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.2202 - accuracy: 0.9400 - val_loss: 0.4404 - val_accuracy: 0.8902\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.1962 - accuracy: 0.9400 - val_loss: 0.6511 - val_accuracy: 0.8049\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 2s 465ms/step - loss: 0.2665 - accuracy: 0.9100 - val_loss: 0.8113 - val_accuracy: 0.8049\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf07d375d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/drive/MyDrive/trail 3 brain tumor dataset/single prediction/no tumor.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'tumor'\n",
        "else:\n",
        "  prediction = 'no tumor'"
      ],
      "metadata": {
        "id": "fQE5UR05j6hZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5ysKO41kDhU",
        "outputId": "3bb2aa1f-4b21-403a-885a-519b5a113ab4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no tumor\n"
          ]
        }
      ]
    }
  ]
}